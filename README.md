Previs√£o de Pre√ßos de Componentes de Computador

Este √© um projeto de Machine Learning que visa desenvolver e avaliar modelos de regress√£o para prever o pre√ßo de componentes de hardware de PC com base em suas especifica√ß√µes t√©cnicas.

O projeto foi desenvolvido como parte da disciplina de Intelig√™ncia Artificial do Curso Ci√™ncia da Computa√ß√£o do IFGoiano Campus Ipor√° e cobre um pipeline completo, desde a coleta e limpeza de dados at√© a otimiza√ß√£o de hiperpar√¢metros e an√°lise de resultados.

---

Objetivos

O objetivo principal deste trabalho foi construir um modelo que pudesse estimar o valor (em Reais - BRL) de um componente de PC. Os objetivos espec√≠ficos inclu√≠ram:

* **Coleta de Dados:** Carregar e consolidar m√∫ltiplos arquivos CSV de diferentes categorias de produtos em um √∫nico dataset.
* **An√°lise Explorat√≥ria (EDA):** Entender a distribui√ß√£o dos dados, identificar a assimetria dos pre√ßos e justificar a transforma√ß√£o logar√≠tmica.
* **Pr√©-processamento:** Implementar um pipeline robusto para tratar valores ausentes (NaNs) e converter dados categ√≥ricos em num√©ricos (One-Hot Encoding).
* **Modelagem (Baseline):** Estabelecer um modelo base de `Regress√£o Linear` para medir a melhoria futura.
* **Modelagem (Avan√ßada):** Implementar um modelo `Random Forest` e avali√°-lo usando Valida√ß√£o Cruzada (K-Fold).
* **Refinamento:** Otimizar os hiperpar√¢metros do `Random Forest` com `RandomizedSearchCV` para encontrar o melhor desempenho poss√≠vel.
* **An√°lise de Performance:** Interpretar os resultados do modelo final, analisando o gr√°fico de Res√≠duos (erros) e o gr√°fico de Import√¢ncia de Features (especifica√ß√µes mais relevantes).

---

Dataset Utilizado(Cr√©ditos)

Este projeto n√£o seria poss√≠vel sem o dataset p√∫blico disponibilizado no Kaggle.

* **T√≠tulo Original:** PC components data set (computer data)
* **Autor:** [sudhanshuy17](https://www.kaggle.com/sudhanshuy17)
* **Fonte:** Kaggle
* **Link:** [https://www.kaggle.com/datasets/sudhanshuy17/pccomponents](https://www.kaggle.com/datasets/sudhanshuy17/pccomponents)

Para este projeto, a coluna de pre√ßo `MRP` (em R√∫pias Indianas - INR) foi limpa e convertida para Reais (BRL), usando uma taxa de c√¢mbio est√°tica para fins de an√°lise.

---

Metodologia e Pipeline

O notebook principal (`.ipynb`) segue um fluxo de trabalho estruturado:

1.  **Carga dos Dados:** O notebook clona o pr√≥prio reposit√≥rio GitHub para acessar os arquivos CSV da pasta `DataSetPcComponents` (anteriormente `Trabalho IA`).
2.  **Limpeza e EDA:** A vari√°vel alvo (pre√ßo) √© limpa e transformada (`np.log1p`) para corrigir a assimetria.
3.  **Pr√©-processamento:**
    * NaNs num√©ricos s√£o preenchidos com `0` (interpretados como "n√£o aplic√°vel").
    * NaNs categ√≥ricos s√£o preenchidos com `"missing"`.
    * Colunas categ√≥ricas s√£o convertidas via `pd.get_dummies`.
4.  **Valida√ß√£o de Modelos:** Os modelos s√£o avaliados usando `cross_val_score` (K=5) sobre o conjunto de treino para uma m√©trica de MAE (Erro M√©dio Absoluto) mais robusta.
5.  **Otimiza√ß√£o:** O `RandomizedSearchCV` (CV=3, n_iter=10) √© usado para "tunar" o Random Forest.
6.  **An√°lise Final:** O melhor modelo √© usado para gerar previs√µes no conjunto de teste (`X_test`), e os gr√°ficos de Res√≠duos e Import√¢ncia de Features s√£o gerados.

---

Principais Resultados

O modelo final (Random Forest Otimizado) demonstrou ser significativamente superior ao baseline de Regress√£o Linear.

* **M√©trica (MAE):** O modelo otimizado atingiu um **Erro M√©dio Absoluto (MAE) de R$ [PREENCHA O MAE FINAL AQUI, ex: R$ 45,80]** no conjunto de teste.
* **Feature Mais Importante:** A an√°lise de `feature_importances_` revelou que a **Categoria** do produto (ex: `Category_GPU`, `Category_Motherboard`) √©, de longe, o fator mais determinante para o pre√ßo.
* **An√°lise de Res√≠duos:** O gr√°fico de res√≠duos mostrou que o modelo √© **altamente preciso para itens de baixo e m√©dio custo**, mas apresenta heteroscedasticidade, tendendo a **subestimar** (chutar para baixo) o pre√ßo de itens *high-end* (muito caros).

---

Como Executar

Este projeto est√° contido em um √∫nico notebook Jupyter e √© configurado para ser totalmente reprodut√≠vel.

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/MateusBrunozi/PricePredictionPcComponentsEDA.git](https://github.com/MateusBrunozi/PricePredictionPcComponentsEDA.git)
    ```
2.  **Abra o Notebook:**
    Carregue o arquivo `.ipynb` no **Google Colab** (recomendado) ou em um ambiente Jupyter local.
3.  **Execute:**
    O notebook est√° configurado (Bloco 2) para clonar este pr√≥prio reposit√≥rio e ler os dados da pasta `DataSetPcComponents`. Basta executar todas as c√©lulas em ordem.

---

Ferramentas Utilizadas

* Python 3
* Pandas
* Numpy
* Matplotlib & Seaborn
* Scikit-learn (para `LinearRegression`, `RandomForestRegressor`, `cross_val_score`, `RandomizedSearchCV`)
* Google Colab

---

## üë®‚Äçüíª Autor

* **Mateus Brunozi** - [GitHub](https://github.com/MateusBrunozi)
